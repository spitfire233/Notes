\documentclass[12pt]{article}

\usepackage{booktabs}% http://ctan.org/pkg/booktabs
\usepackage[utf8]{inputenc}
\usepackage{changepage}
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{adjustbox}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{biblatex}
\usepackage{algorithm2e}
\RestyleAlgo{ruled}
\SetKwProg{Proc}{Procedure}{:}{}


\lstset{
  language=Python,
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  tabsize=4,
  basicstyle=\ttfamily,
  columns=fullflexible,
  keepspaces,
}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{graphicx}
\newenvironment{para}{\begin{adjustwidth}{13mm}{}}{\end{adjustwidth}}

\newcommand\tab[1][1cm]{\hspace*{#1}}

\newcommand{\tabitem}{\llap{\textbullet}}
\newcommand{\Hsquare}{%
\text{\fboxsep=-.2pt\fbox{\rule{0pt}{1ex}\rule{1ex}{0pt}}}%
}

\newtheorem{Definizione}{Definizione}[subsection]
\newtheorem{Lemma}{Lemma}[subsection]
\newtheorem{Teorema/Definizione}{Teorema/Definizione}[subsection]
\newtheorem{Corollario}{Corollario}[subsection]
\newtheorem{Teorema}{Teorema}[subsection]
\newtheorem{Proposizione}{Proposizione}[subsection]
\newtheorem{Notazione}{Notazione}[subsection]
\newtheorem{Commento}{Commento}[subsection]
\newtheorem{Dimostrazione}{Dimostrazione}[subsection]
\newtheorem{Osservazione}{Osservazione}[subsection]
\newtheorem{Nota}{Nota}[subsection]

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\title{Analisi e Progetto di Algoritmi}
\author{spitfire}
\date{A.A. 2024-2025}
\begin{document}
\begin{figure}
    \centering
    \includegraphics[width=0.35\textwidth]{Images/Logo scienze bicocca.png}
\end{figure}

\vspace{10cm}
\date{A.A. 2024-2025}


\maketitle

\newpage

\tableofcontents
\newpage

\section{Introduzione}
Prima di vedere gli argomenti del corso, facciamo un breve ripasso delle nozioni fondamentali per
lo studio degli algoritmi.
\subsection{Crescita delle funzioni}
Le notazioni che usiamo per descrivere il tempo di esecuzione asintotico di un algoritmo sono definite in termini di funzioni
il cui dominio è l'insieme dei numeri naturali $\mathbb{N} = \{0,1,...\}$. In particolare, indichiamo con:
$$T: \mathbb{N} \rightarrow \mathbb{R}^+$$
la funzione che indica i tempi di calcolo di un algoritmo. Assumiamo che $n$ sia la dimensione dell'input per un certo algoritmo, allora 
$T(n)$ indica il \textbf{tempo di calcolo calcolo (costo computazionale) dell'algoritmo in base alla dimensione dell'input}.
È molto raro avere un espressione ben definita per $T$; infatti molto più spesso interessa maggiormente "come cresce $T$" o più precisamente
\textbf{"$T$ cresce come quale funzione?"}. Siano $g: \mathbb{R} \rightarrow \mathbb{R}^+$ e $f: \mathbb{R}^+ \rightarrow \mathbb{R}^+$ due funzioni (che però applicheremo solo ai naturali).
Diciamo che:
$$\Theta(g(n)) = \left \{f(n)\middle|\exists c_1 >0, c_2 > 0, n_0 \in \mathbb{N}\middle| \forall n \geq n_0, c_1 g(n) \leq f(n) \leq c_2 g(n)\right \}$$
$g(n)$ quindi si dice un \textbf{limite asintotico stretto} per $f$. Una funzione $f(n)$ quindi appartiene a $\Theta(g(n))$ se esistono delle costanti positive $c_1,c_2$ tali che essa possa essere "racchiusa" fra $c_1g(n)$ e $c_2g(n)$ per valori
sufficientemente grandi di $n$. \newline
Se vale solamente che $f(n) \leq c g(n)$ per una qualche costante $c$ allora si dice che $g$ è un \textbf{limite asintotico superiore per $f$} e si indica con $\mathcal{O}(g(n))$. \newline
Se vale solamente che $c g(n) \leq f(n)$ per una qualche costante $c$ allora si dice che $g$ è un \textbf{limite asintotico inferiore per $f$} e si indica con $\Omega(g(n))$. \newline
\begin{center}
    \includegraphics[width = 1\linewidth]{Images/1.png}
\end{center}
Riportiamo qui di sotto la gerarchia di crescita delle funzioni:
$$\textrm{costante} < \log{n} < n < n \cdot \log n < n^k < 2^n < n! < n^n \; \; \textrm{con } k > 0$$
\subsection{Metodi di risoluzione delle ricorrenze}
Una ricorrenza è un'equazione o disequazione che descrive una funzione
in termini del suo valore con input più piccoli. Vi sono diversi modi per risolvere una ricorrenza:
\begin{itemize}
    \item \textbf{Metodo di sostituzione}: si ipotizza un limite e poi si utilizza l'induzione matematica per dimostrare che l'ipotesi è corretta
    \item \textbf{Metodo dell'albero di ricorsione}: Converte la ricorrenza in un albero i cui nodi rappresentano i costi ai vari livelli della ricorsione.
    \item \textbf{Metodo dell'esperto}: fornice i limiti per le ricorrenze nella forma:
    $$T(n) = aT(\frac{n}{b}) + f(n)$$
    dove $a \geq 1, b>1$ e $f(n)$ è una funzione data. 
\end{itemize}
Possiamo dividere le ricorrenze in due tipi:
\subsubsection{Relazioni di ricorrenza lineari}
\begin{Definizione}
Una relazione di ricorrenza lineare di ordine $r$ è una relazione del tipo:
$$a_n = c_1a_{n-1} + c_2a_{n-2} + ... + c_ra_{n-r} + f(n)$$
dove $c_1, ..., c_r$ sono costanti e $f$ è una funzione di $n$
\end{Definizione}
\begin{Definizione}
    Una relazione di ricorrenza lineare è \textbf{omogenea} di ordine $r$ se è una relazione
    del tipo:
    $$a_n = c_1a_{n-1} + c_2a_{n-2} + ... + c_ra_{n-r}$$
    dove $c_1,...,c_r$ sono costanti
\end{Definizione}
Chiaramente, ogni relazione di ricorrenza lineare omogenea ha la successione identicamente nulla come soluzione.
Analogamente a quanto capita per le equazioni lineari omogenee, si verifica facilmente che combinazioni lineari di soluzioni
di una relazione omogenea sono ancora soluzioni.
\begin{Definizione}
    Diciamo \textbf{polinomio caratteristico} di una relazione di ricorrenza lineare omogenea $R_0$ di ordine $r$ il polinomio:
    $$x^r - c_1x^{r-1} - ... - c_r$$
\end{Definizione}
Vale la seguente proposizione:
\begin{Proposizione}
    Sia $\lambda$ una radice del polinomio caratteristico di una relazione lineare omogenea. Allora la successione $(\lambda^n)_n$ è una soluzione della relazione.
\end{Proposizione}
Vale inoltre, in generale, il seguente teorema:
\begin{Teorema}
    Si consideri una relazione di ricorrenza lineare omogenea di ordine $r$:
    \begin{enumerate}
        \item Supponiamo che la radice $\lambda$ del polinomio caratteristico abbia molteplicità $\mu$. Allora:
        $$\lambda^n, \lambda^n n,\dots,\lambda^n n^{\mu - 1}$$
        sono soluzioni della relazione di ricorrenza. Al variare di $\lambda$ tra le radici del polinomio caratteristico si ottengono $r$ soluzioni di questo tipo, dette le \textbf{soluzioni-base} della relazione.
        \item La soluzione generale della relazione è data da tutte le combinazioni lineari (a coefficienti complessi) delle $r$ soluzioni-base della relazione.
    \end{enumerate}
\end{Teorema}
Analizziamo ora una generica relazione lineare di ordine $r$
$$a_n = c_1a_{n-1} + c_2a_{n-2} + ... + c_ra_{n-r} + f(n)$$
Chiameremo ancora polinomio caratteristico della relazione il polinomio caratteristico della \textbf{relazione omogenea associata}.
\begin{Proposizione}
    La soluzione generale di una relazione di ricorrenza lineare si ottiene aggiungendo una soluzione particolare alla soluzione generale della sua parte omogenea.
\end{Proposizione}
\begin{Proposizione}
    Si consideri una relazione di ricorrenza lineare con parte non omogenea $f$.
    \begin{enumerate}
        \item Sia $f(n) = cq^n$ con $c$ costante e $q \neq 0$. Se $q$ \textbf{non è una radice del polinomio caratteristico}, allora vi è una
        soluzione particolare del tipo $a_n = \alpha q^n$. Se $q$ \textbf{è una radice del polinomio caratteristico di molteplicità} $\mu$, vi è una
        soluzione particolare del tipo $a_n = \alpha n^\mu q^n$. La costante $\alpha$ si determina imponendo che la successione $(a_n)_n$ verifichi la relazione.
        \item Sia $f(n)$ un polinomio in $n$ di grado $k$. Se $1$ \textbf{non è una radice del polinomio caratteristico}, una soluzione particolare è un polinomio di grado $k$ del tipo:
        $$a_n = \alpha_0 + \alpha_1 n + \dots + a_k n^k$$
        Se $1$ \textbf{è una radice del polinomio caratteristico di molteplicità $\mu$}, una soluzione particolare è del tipo $a_n = n^\mu(\alpha_0 + \alpha_1 n + \dots + a_k n^k)$.
        Le costanti $\alpha_0, ..., \alpha_k$ si determinano imponendo che la successione $(a_n)_n$ verifichi la relazione
    \end{enumerate}
\end{Proposizione}
\begin{Corollario}
    Una relazione di ricorrenza lineare il cui termine non omogeneo è costante ammette:
    \begin{itemize}
        \item Una soluzione costante se $1$ \textbf{non è radice del polinomio caratteristico}
        \item Una soluzione del tipo $\alpha n^\mu$ se $1$ è \textbf{radice di molteplicità $\mu$ del polinomio caratteristico}
    \end{itemize}
\end{Corollario}
Una relazione di ricorrenza lineare può essere risolta anche \textbf{osservando che $r^n$ è una soluzione per particolari valori di $r$}.
Per relazioni di ricorrenza della forma:
$$x_n = Ax_{n-1} + Bx_{n-2}$$
si ha la soluzione $r^n$ per la quale:
$$r^n = Ar^{n-1} + Br^{n-2}$$
dividendo tutti i termini per $r^{n-2}$ si ottiene:
$$r^2 = Ar + B$$
ossia
$$r^2 - Ar - B = 0$$
che viene chiamata \textbf{equazione caratteristica della relazione di ricorrenza}. Essa fornisce per $r$ due radici
$\lambda_1, \lambda_2$. Se tali radici sono \textbf{distinte} si ha la soluzione:
$$x_n = C\lambda_1^n + D\lambda_2^n$$
se invece le due radici \textbf{coincidono}, cioè se $A^2 +4B = 0$ si ha:
$$x_n = C\lambda^n + Dn\lambda^n$$
dove $C$ e $D$ sono costanti arbitrarie che possono essere ricavate da "condizioni al contorno" che tipicamente
sono date nella forma:
$$x_0 = a, \; \; x_1 = b$$
\subsubsection{Metodo di sostituzione}
Il metodo di \textbf{sostituzione} per risolvere le ricorrenze richiede due passi:
\begin{enumerate}
    \item Ipotizzare la forma della soluzione
    \item Usare l'induzione matematica per trovare le costanti e dimostrare che la soluzione funziona
\end{enumerate}
Il nome del metodo deriva dalla sostituzione della soluzione ipotizzata al posto della funzione quando l'ipotesi induttiva viene
applicata a valori più piccoli. Questo metodo è potente, ma ovviamente può essere applicato solamente a ricorrenze di cui
sia facile immaginare la forma della soluzione. Inoltre, non esiste un metodo generale per effettuare una buona ipotesi, quindi bisogna
basarsi molto spesso sull'esperienza oppure controllare se la ricorrenza considerata è simile a ricorrenze di cui si conoscono già i limiti
asintotici. Altri metodi per risolvere le problematiche di questo metodo sono:
\begin{itemize}
    \item \textbf{Effettuare ipotesi "lasche"} e man mano diminuire il grado di incertezza (cioè, restringere le ipotesi fino ad arrivare ad un limite stretto)
    \item \textbf{Sottrarre un termine di grado inferiore}, sopratutto in ricorrenze in cui l'ipotesi induttiva non è abbastanza forte per dimostrare il limite esatto per colpa di una costante
    \item \textbf{Sostituzioni di variabili}
\end{itemize}
\subsubsection{Metodo dell'albero di ricorsione}
In un \textbf{albero di ricorsione}, ogni nodo rappresenta il costo di un \textbf{singolo sotto-problema} da qualche parte nell'insieme
delle chiamate ricorsive di funzione. Sommiamo i costi all'interno di ogni livello dell'albero per ottenere un insieme di costi per livello;
poi sommiamo tutti i costi per livello per determinare il costo totale di tutti i livelli della ricorsione.
Un albero di ricorsione è un ottimo modo per \textbf{ottenere una buona ipotesi} che verrà poi verificata tramite il \textbf{metodo di sostituzione}; tuttavia
può essere usato anche come metodo risolutivo diretto.
\begin{center}
    \includegraphics[width = 1\linewidth]{Images/2.png}
\end{center}
\begin{center}
    \includegraphics[width = 1\linewidth]{Images/3.png}
\end{center}
\subsubsection{Metodo dell'esperto}
Il metodo dell'esperto permette di risolvere le ricorrenze della forma:
$$T(n) = aT(\frac{n}{b}) + f(n)$$
dove $a \geq 1, b >1$ sono costanti e $f(n)$ è una funzione \textbf{asintoticamente positiva}.
Il metodo dell'esperto dipende dal seguente teorema:
\begin{Teorema}[Teorema dell'esperto]
    Date le costanti $a \geq 1, b > 1$ e la funzione $f(n)$, sia $T(n)$ una funzione definita sugli interi non negativi dalla ricorrenza
    $$T(n) = aT(\frac{n}{b}) + f(n)$$
    dove $\frac{n}{b}$ rappresenta $\floor{\frac{n}{b}}$ o $\ceil{\frac{n}{b}}$. Allora $T(n)$ può essere asintoticamente limitata nei seguenti modi:
    \begin{enumerate}
        \item Se $f(n) = \mathcal{O}(n^{\log_b{a - \varepsilon}})$ per qualche costante $\varepsilon > 0$, allora $T(n) = \Theta(n^{lob_b{a}})$
        \item Se $f(n) = \Theta(n^{\log_b{a}})$ allora $T(n) = \Theta(n^{\log_b{a}} \log{n})$
        \item Se $f(n) = \Omega(n^{log_b{a} + \varepsilon})$ per qualche costante $\varepsilon > 0$ e se $f(\frac{n}{b}) \leq c f(n)$ per qualche costante $c < 1$ e per ogni
        $n$ sufficientemente grande, allora $T(n) = \Theta(f(n))$
    \end{enumerate}
\end{Teorema}
Questo metodo si utilizza principalmente per risolvere le ricorrenze che descrivono i tempi di calcolo degli algoritmi
\textbf{dividi-et-impera}
\section{Programmazione dinamica}
La programmazione dinamica risolve i problemi combinando le soluzioni dei sotto-problemi.
La tecnica dividi-et-impera, divide il problema in sotto-problemi \textbf{indipendenti}, li risolve in modo ricorsivo e, poi, combina
le loro soluzioni per risolvere il problema originale. La programmazione dinamica, invece, può essere applicata quando \textbf{i sotto-problemi non sono indipendenti},
ovvero quando i sotto-problemi hanno \textbf{in comune dei sotto-problemi}. In questo contesto, un algoritmo dividi-et-impera \textbf{svolge molto più lavoro del necessario},
risolvendo \textbf{ripetutamente i sotto-problemi comuni}. Un algoritmo di programmazione dinamica invece \textbf{calcola una sola volta i risultati dei sotto-problemi} e li
salva in una tabella, evitando quindi di ricalcolarli ogni volta che essi si presentano. La programmazione dinamica tendenzialmente si applica ai \textbf{problemi di ottimizzazione}.
Per questi problemi ci possono essere molte soluzioni possibili; quindi si vuole trovare una soluzione con \textbf{valore ottimo} (minimo o massimo). Precisiamo che abbiamo detto \textbf{UNA} soluzione
ottima e non \textbf{LA} soluzione ottima poiché ci possono essere più soluzioni che raggiungono il valore ottimo.
Il processo di sviluppo di un algoritmo di programmazione dinamica può essere suddiviso in una sequenza di quattro fasi:
\begin{enumerate}
    \item Caratterizzare la struttura di una soluzione ottima
    \item Definire in modo ricorsivo il valore di una soluzione ottima
    \item Calcolare il valore di una soluzione ottima, di solito con uno schema bottom-up (dal basso verso l'alto)
    \item Costruire una soluzione ottima dalle informazione calcolate (algoritmo di \textbf{ricostruzione})
\end{enumerate}
Durante la fase 4 possiamo memorizzare anche \textbf{informazioni aggiuntive} utili a semplificare il processo di ricostruzione.
Facciamo un esempio: consideriamo un algoritmo ricorsivo che dia in output l'n-esimo numero di fibonacci: \newline
\begin{algorithm}[H]
\caption{Algoritmo ricorsivo che calcola l'n-esimo numero di fibonacci}
\DontPrintSemicolon
\SetKwFunction{FFibRic}{Fib-Ric}
\Proc{\FFibRic{n}} {
    \eIf{n $\leq$ 1} {
        \Return 1
    } {
        \Return Fib-Ric(n-1) + Fib-Ric(n-2)
    }
}
\end{algorithm}
\noindent
La sua equazione di ricorrenza è:
$$T(n) = T(n-1) + T(n-2) + 2$$
Se provassi a sviluppare la ricorrenza, finirei in un \textbf{loop infinito}. 
Proviamo quindi il metodo dell'albero di ricorsione; supponiamo $n = 5$:
\begin{center}
    \includegraphics[width = 1\linewidth]{Images/4.png}
\end{center}
notiamo quindi che l'algoritmo \textbf{non si accorge che alcuni calcoli si ripetono}. Notiamo quindi
che l'equazione di ricorrenza è una \textbf{ricorrenza lineare non omogenea}; consideriamo quindi l'equazione
di ricorrenza omogenea associata:
$$T(n) = T(n-1) + T(n-2)$$
supponiamo che $r^n$ è una soluzione:
$$r^n = r^{n-1} + r^{n-2}$$
moltiplichiamo entrambi i lati per $r^2$ e otteniamo:
$$r^2 \cdot r^n = r \cdot r^n + r^n$$
dividiamo entrambi i lati per $r^n$ e otteniamo:
$$r^2 = r + 1 \Rightarrow r^2 - r - 1 = 0$$
il quale è anche il polinomio caratteristico della ricorrenza. Il discriminante di questa equazione di secondo grado è $\Delta = 5$, quindi le due radici del polinomio sono:
$$r_{1,2} = \frac{1 \pm \sqrt{5}}{2}$$
notiamo quindi che la supposizione $T(n) = r^n$ è vera! Poiché $r_1 \neq r_2$ allora l'equazione di ricorrenza omogenea associata diventa:
$$T(n) = c_1 \left (\frac{1 + \sqrt{5}}{2} \right )^n + c_2 \left (\frac{1 - \sqrt{5}}{2} \right )^n$$
per risolvere la ricorrenza, dobbiamo aggiungere una soluzione particolare alla soluzione generale dell'equazione di ricorrenza omogenea associata (Proposizione 1.2.2), cioè quindi dobbiamo
trovare un certo $k$ tale che:
$$T(n) = c_1 \left (\frac{1 + \sqrt{5}}{2} \right )^n + c_2 \left (\frac{1 - \sqrt{5}}{2} \right )^n + k$$
notiamo che la parte non omogenea $f(n)$ della ricorrenza iniziale è costante, quindi dal Corollario 1.2.1 sappiamo che una soluzione particolare
della ricorrenza è \textbf{costante}, in particolare essa è $-2$. Quindi
$$T(n) = c_1 \left (\frac{1 + \sqrt{5}}{2} \right)^n + c_2 \left (\frac{1 - \sqrt{5}}{2} \right )^n - 2 = \Theta\left ( \left (\frac{1 + \sqrt{5}}{2} \right )^n \right )$$
come possiamo riscrivere iterativamente l'algoritmo? \newline
\begin{algorithm}[H]
    \caption{Algoritmo iterativo che calcola l'n-esimo numero di fibonacci}
    \DontPrintSemicolon
    \SetKwFunction{FFibIt}{Fib-It}
    \Proc{\FFibIt{n}} {
        Sia F[0,...,n] un array\;
        F[0] := 1\;
        F[1] := 1\;
        \For{$i \gets 2$ \KwTo n} {
            F[i] := F[i-1] + F[i-2]\;
        }
        \Return F[n]
    }
\end{algorithm}
\noindent
Il tempo di calcolo di questo algoritmo è $T(n) = \Theta(n)$, tuttavia viene "sprecato" dello spazio in memoria per \textbf{memorizzare l'array}.
Notiamo che l'istruzione all'interno del for \textbf{è praticamente uguale alla relazione di ricorrenza presentata in precedenza}; la programmazione dinamica
è quindi \textbf{strettamente legata alla ricorsione} e a come essa \textbf{definisce la STRUTTURA della soluzione}.
\subsection{LCS - Longest Common Subsequence}
Sia $X = <x_1,...,x_m>$ una sequenza con elementi provenienti da un alfabeto $\Sigma$, quindi $x_i \in \Sigma \; \forall i = 1,...,m$.
\begin{Definizione}
    $Z = <z_1,\dots,z_k>$ è \textbf{sottosequenza} di $X$ se e solo se esiste una sequenza \textbf{strettamente crescente di indici} $<i_1,\dots,i_k>$ tali che $\forall i \in [1,k] \; z_j = x_{i_j}$
\end{Definizione}
\begin{Nota}
    Non devono per forza essere consecutivi!
\end{Nota}
Sia ora $X = <x_1,\dots,x_n>$ una sequenza e sia $i \in \{1,\dots,n\}$; allora
\textbf{il prefisso i-esimo di $X$} viene indicato con $X_i = <x_1,\dots,x_i>$ con $X_0 = \varepsilon$ che indica
\newpage
la \textbf{sequenza vuota}. Facciamo due considerazioni:
\begin{itemize}
    \item $X_i$ \textbf{è sottosequenza} di $X$
    \item $X_n = X$ se $X$ ha lunghezza $n$
\end{itemize}
Diamo ora la formulazione formale del problema: \newline
\textbf{\underline{PROBLEMA}}: Date due sequenze $X$ e $Y$, rispettivamente di $m$ ed $n$ numeri interi, si determini \textbf{UNA} tra le più lunghe sottosequenze comuni a $X$ e $Y$. \newline
\textbf{\underline{ISTANZA}}: $X = <x_1,\dots,x_m>$ e $Y = <y_1,\dots,y_n>$ \newline
\textbf{\underline{SOLUZIONE}}: $Z$ sottosequenza sia di $X$ che di $Y$ tale che \newline $|Z| = \max\{|W|: \textrm{W è sottosequenza sia di X che di Y}\}$
\begin{Nota}
    Notare che il la definizione del problema non è ricorsiva!
\end{Nota}
Come possiamo quindi "sfruttare" la ricorsione per raggiungere una soluzione del problema?
Dobbiamo \textbf{individuare un sottoproblema}; che in questo caso "lavorerà" con i \textbf{prefissi}
di $X$ e $Y$. Un sottoproblema del problema originale è quindi il seguente: \newline
\textbf{\underline{ISTANZA DEL SOTTOPROBLEMA}}: $X_i = <x_1,...,x_i>$ e $Y_j = <y_1,...,y_j>$ \newline
\textbf{\underline{SOLUZIONE}}: $LCS(X_i, Y_j) = S^{(i,j)}$ \newline
Quindi per risolvere un problema ricorsivo, \textbf{devo immaginare di aver già risolto tutti i sottoproblemi più piccoli}, quindi di aver già risolto:
$$S^{m-1, n}, S^{m-2, n}, \dots, S^{0, n}$$
$$S^{m-1, n-1}, S^{m-2, n-1}, \dots S^{0, n-1}, \dots$$
Quindi come andiamo a definire $S^{(m, n)}$?
essa contiene \textbf{tutti i sottoproblemi risolti, combinati in una certa maniera}. \newline
Il sottoproblema generico è quindi individuato da una coppia $(i,j)$ tale che:
$$0 \leq i \leq m$$
$$0 \leq j \leq n$$
Definiamo allora il problema ricorsivamente: \newline
\textbf{\underline{CASO BASE}}: $i = 0 \vee j = 0$; allora 
$S^{(i,j)} = \varepsilon$ \newline
\textbf{\underline{PASSO RICORSIVO}}: $i > 0 \land j > 0$ \newline
Dobbiamo distinguere due casi:
\begin{itemize}
    \item Se $x_i = y_j$ allora $S^{(i,j)} = S^{(i-1, j-1)}|x_i$ (con $|$ che significa "accodo")
    \item Se $x_i \neq y_j$ allora:
    $$S^{(i,j)}\begin{cases}
        S^{(i-1, j)} \; \; \textrm{Se } |S^{(i-1, j)}| > |S^{(i, j-1)}| \\
        S^{(i, j-1)} \; \; \textrm{Altrimenti}
    \end{cases}$$
\end{itemize}
Questa però \textbf{non è una dimostrazione}; per dimostrare che effettivamente la soluzione abbia questa struttura dobbiamo introdurre il
concetto di \textbf{proprietà della sottostruttura ottima (PSO)}:
\begin{Teorema}[PSO della LCS]
    Siano $X_m, Y_n$ le sequenze e sia $Z_k$ una LCS di $X_m$ e $Y_n$. Allora:
    \begin{enumerate}
        \item Se $x_m = y_n$ allora $z_k = x_m = y_n$ e $Z_{k-1}$ è una LCS di $X_{m-1}$ e $Y_{n-1}$
        \item Se $x_m \neq y_n$ e $z_k \neq x_m$ allora $Z_k$ è una LCS di $X_{m-1}$ e $Y_n$
        \item Se $x_m \neq y_n$ e $z_k \neq y_n$ allora $Z_k$ è una LCS di $X_m$ e $Y_{n-1}$
    \end{enumerate}
\end{Teorema}
\begin{Dimostrazione}
    Dimostriamo tutti i casi del teorema sopra:
    \begin{enumerate}
        \item Se $x_m = y_n$
        \begin{enumerate}
            \item Facciamo vedere che $z_k = x_m = y_n$. Se per assurdo $z_k \neq x_m \vee z_k \neq y_n$ allora potrei
            costruire una sequenza $Z_k|x_m$; tuttavia essa sarebbe una LCS di lunghezza maggiore di $Z_k$, il chè è \textbf{assurdo} poiché
            $Z_k$ è la LCS tra $X_m$ e $Y_n$.
            \item Facciamo vedere che $Z_{k-1} = LCS(X_{m-1}, Y_{n-1})$. Assumiamo per assurdo che $Z_{k-1}$ non è una LCS di $X_{m-1}$ e $Y_{n-1}$.
            Sia $Z'$ una LCS di $X_{m-1}$ e $Y_{n-1}$, allora $|Z'| > k-1$; quindi potrei costruire una sequenza $Z'|x_m$, la quale è una sottosequenza comune
            di $X_m$ e $Y_n$. Inoltre, $|Z'|x_m| > k$, tuttavia ciò contraddice il fatto che $Z_k$ sia una LCS tra $X_m$ e $Y_n$, quindi è \textbf{assurdo}
        \end{enumerate}
        \item Se $x_m \neq y_n \land z_k \neq x_m$, allora devo far vedere che $Z_k = LCS(X_{m-1}, Y_n)$. Assumiamo per assurdo $Z_k$ non è una $LCS(X_{m-1}, Y_n)$.
        Sia $Z'$ una $LCS(X_{m-1}, Y_n)$, allora $|Z'| > k$. Inoltre, $Z'$ è anche sottosequenza di $X_m$ e $Y_n$, tuttavia ciò implicherebbe che $Z_k$ non può essere una $LCS(X_m, Y_n)$, il che è \textbf{assurdo}
        \item Simmetrica a quella del punto 2
    \end{enumerate}
\end{Dimostrazione}
\begin{algorithm}[H]
    \caption{Algoritmo ricorsivo che stampa la LCS tra due sequenze $X_m$ e $Y_n$}
    \DontPrintSemicolon
    \SetKwFunction{FLCSRic}{LCS-Ric}
    \Proc{\FLCSRic{X, Y, i, j}} {
        \eIf{$i = 0 \vee j = 0$} {
            \Return $\varepsilon$
        } {
            \eIf{$x_i = y_j$} {
                \Return LCS-Ric(X, Y, i-1, j-1)|$x_i$
            }  {
                A := LCS-Ric(X, Y, i-1, j) \;
                B := LCS-Ric(X, Y, i, j-1) \;
                \eIf{$|A| \geq |B|$} {
                    \Return A
                } {
                    \Return B
                }
            }
        }
    }
\end{algorithm}
Notiamo che seppur tratti della struttura della soluzione, \textbf{non possiamo derivare un algoritmo basandoci unicamente sulla PSO}; infatti io non conosco il valore di $z_k$!.
Tuttavia, se nella caratterizzazione della sottostruttura ottima sia si utilizzano sia gli input che le caratteristiche della sottostruttura ottima,
\textbf{posso comunque arrivare ad un algoritmo anche in caso di mancanza di informazione}, a patto che \textbf{tutti i casi siano coperti}. Poiché è questo il caso, possiamo derivare l'algoritmo
sopra riportato. La complessità dell'algoritmo 3 tuttavia \textbf{è altissima}; abbiamo però a disposizione \textbf{tutte le informazioni necessarie per applicare la programmazione dinamica e scrivere un algoritmo iterativo che calcoli la LCS tra $X_m$ e $Y_n$}: \newline
\begin{algorithm}[H]
    \caption{Un algoritmo iterativo che stampa una LCS tra $X_m$ e $Y_n$}
    \DontPrintSemicolon
    \SetKwFunction{FLCSIt}{LCS-It}
    \Proc{\FLCSIt{X, Y}} {
        m = LENGTH(X) \;
        n = LENGTH(Y) \;
        \For{$j \gets 0$ to $n$} {
            S[0,j] := $\varepsilon$
        }
        \For{$i \gets 0$ to $m$} {
            S[i,0] := $\varepsilon$
        }
        \For{$i \gets 1$ to $m$} {
            \For{$j \gets 1$ to $n$} {
                \eIf{$x_i = y_j$} {
                    S[i,j] := S[i-1, j-1]|$x_i$
                } {
                    \eIf{LENGTH(S[i-1,j]) $\geq$ LENGTH(S[i, j-1])} {
                        S[i, j] := S[i-1, j]
                    } {
                        S[i,j] := S[i, j-1]
                    }
                }
            }
        }
        \Return S[m,n]
    }
\end{algorithm}
\noindent
Ci avvaliamo quindi di una \textbf{matrice} $m \times n$ S per \textbf{salvare i risultati dei sottoproblemi}.
La soluzione del problema si troverà quindi nella cella [m,n] della matrice. Il \textbf{tempo di calcolo} di questo algoritmo è:
$$T(n) = \Theta(m \cdot n)$$
tuttavia, vi è uno \textbf{spreco di memoria per memorizzare la matrice}, vista che ogni cella contiene una \textbf{sottosequenza}.
Possiamo quindi lavorare come una \textbf{versione ridotta del problema}, il quale ha la seguente formulazione: \newline
\textbf{\underline{PROBLEMA RIDOTTO}}: Date due sequenze $X$ e $Y$, rispettivamente di $m$ ed $n$ numeri interi, si determini \underline{la lunghezza} di una tra le più lunghe sottosequenze comuni a $X$ e $Y$. \newline
Anche il problema ridotto contiene \textbf{diversi sottoproblemi}, ognuno dei quali non ha come input la coppia $(X,Y)$ ma una coppia di prefissi di tali sequenze. Ogni sottoproblema è quindi
\textbf{identificato da una coppia $(i,j)$} ed è definito come segue: \newline
\textbf{SOTTOPROBLEMA GENERICO}: Date due sequenze $X$ e $Y$, rispettivamente di $m$ ed $n$ numeri interi, si determini la lunghezza di una tra le più lunghe sottosequenze comuni al prefisso $X_i$ e al prefisso $Y_j$. \newline
Anche in questo caso, dato che $0 \leq i \leq m$ e $0 \leq j \leq n$, si ottengono $(m+1) \cdot (n+1)$ sottoproblemi ($i$ e $j$ possono valere 0 in quanto si deve considerare anche il caso in cui un prefisso sia la sequenza vuota).
Ad ogni sottoproblema del problema ridotto \textbf{è associata una variabile}: considerato il sottoproblema di dimensione $(i,j)$, la variabile ad esso associata è $c_{i,j}$ ed è così definita:
$$c_{i,j} := \textrm{lunghezza di una tra le più lunghe sottosequenze comuni a } X_i \; e \; Y_j$$
Per determinare la soluzione di un qualsiasi sottoproblema di dimensione $(i,j)$, oltre all'input, si utilizzeranno le soluzione dei sottoproblemi di dimensione minore (come nel caso visto prima).
Si noti però che ogni variabile associata ad un sottoproblema è da considerare come una \textbf{black-box}: si può utilizzare ma non è possibile conoscerne il contenuto.
Scriviamo l'equazione di ricorrenza del problema ridotto: \newline
\textbf{\underline{CASO BASE}}: $(i,j)$ con $i = 0 \vee j = 0$. \newline
Il caso base si ha per un qualunque sottoproblema di dimensione $(i,j)$ con $i = 0 \vee j = 0$, ossia quando uno dei due prefissi considerati è la sequenza vuota.
In questo caso, è facile ottenere il valore della variabile $c_{i,j}$ in quanto la lunghezza di una tra le più lunghe sottosequenze comuni fra una qualsiasi fra una qualsiasi sequenza e la sequenza vuota è 0 (ossia la lunghezza della sequenza vuota).
Per questa ragione, il caso base è scrivibile come:
$$c_{i,j} = 0 \; \textrm{se } i = 0 \vee j = 0$$
\textbf{\underline{PASSO RICORSIVO}}: $(i,j)$ con $i > 0 \land j > 0$ \newline
Il passo ricorsivo si ha per un qualunque sottoproblema di dimensione $(i,j)$ con $i > 0 \land j > 0$, ossia quando si vanno a considerare due prefissi
$X_i = <x_1,\dots,x_i$ e $Y_j = <y_1,\dots,y_j>$ entrambi diversi dalla sequenza vuota. I dati disponibili per calcolare $c_{i,j}$ sono:
\begin{itemize}
    \item L'input $X$ ed in particolare l'elemento $x_i$
    \item L'input $Y$ ed in particolare l'elemento $y_j$
    \item Tutte le variabili $\{c_{0,0}, \dots, c_{i-1, j}, c_{i, j-1} \}$
\end{itemize}
Per calcolare $c_{i,j}$ è necessario applicare il \textbf{teorema della proprietà della sottostruttura ottima} (Teorema 2.1.1), di cui ciò che segue è una conseguenza:
\begin{itemize}
    \item Se $x_i = y_j$: se i due elementi considerati sono identici allora la lunghezza della più lunga sottosequenza comune fra $X_i$ e $Y_j$ è uguale alla lunghezza della più lunga sottosequenza comune fra $X_{i-1}$ e $Y_{j-1}$ (ossia il valore di $c_{i-1,j-1}$)
    aumentata di uno (l'elemento comune $x_i$ è accodato ad una più lunga sottosequenza comune a $X_{i-1}$ e $Y_{j-1}$ correlata al sottoproblema di dimensione ($i-1, j-1$) e che quindi lunghezza $c_{i-1,j-1}$).
    In altri termini, se $Z_k$ è una LCS fra $X_i$ e $Y_j$, allora $z_k = x_i = y_j$ e $Z_{k-1} = LCS(X_{i-1}, Y_{j-1})$
    \begin{center}
        \includegraphics[width = 0.50\linewidth]{Images/5.png}
    \end{center}
    quindi $c_{i,j} = 1 + c_{i-1, j-1} \; \; \textrm{se } x_i = y_j$
    \item Se $x_i \neq y_j$ i due elementi considerati sono differenti, allora la lunghezza della più lunga sottosequenza comune è data dalla soluzione di uno dei sottoproblemi di dimensione minore.
    Siccome gli elementi finali dei due prefissi considerati sono differenti, non possono appartenere entrambi alla soluzione $Z_k$ e risulta necessario considerare i seguenti due casi, sulla base di come è fatto l'ultimo elemento $z_k$ della soluzione $Z_k$:
    \begin{itemize}
        \item 
    \end{itemize}
\end{itemize}


\end{document}
